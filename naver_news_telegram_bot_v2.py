import requests
from bs4 import BeautifulSoup
import telegram
from datetime import datetime
import asyncio
# python-telegram-bot v20+ì— ë§ëŠ” import êµ¬ë¬¸ìœ¼ë¡œ ìˆ˜ì •
from telegram import Bot
from telegram.constants import ParseMode
from telegram.error import TelegramError
import os
from playwright.async_api import async_playwright
import json

# --- í…”ë ˆê·¸ë¨ ë´‡ ì„¤ì • ---
# â€» ë³´ì•ˆì„ ìœ„í•´ ë´‡ í† í°ê³¼ ì±„íŒ… IDëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.
# ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸í•  ê²½ìš°, ì•„ë˜ ë¬¸ìì—´ì— ì§ì ‘ ê°’ì„ ì…ë ¥í•´ë„ ë©ë‹ˆë‹¤.
# ì˜ˆ: TELEGRAM_BOT_TOKEN = "12345:ABCDE..."
TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN', "")
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID', "")

def escape_markdown_v2(text):
    """Telegram MarkdownV2 íŒŒì‹±ì„ ìœ„í•œ íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬"""
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return "".join(['\\' + char if char in escape_chars else char for char in str(text)])

async def send_message(final_message):
    """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜"""
    bot = telegram.Bot(token=TELEGRAM_BOT_TOKEN)
    await bot.send_message(
        chat_id=TELEGRAM_CHAT_ID,
        text=final_message,
        parse_mode='MarkdownV2',
        disable_web_page_preview=True
    )

async def click_until_disappear(page, button_class):
    """ë²„íŠ¼ì´ ì‚¬ë¼ì§ˆ ë•Œê¹Œì§€ 3ì´ˆë§ˆë‹¤ ì²´í¬í•˜ë©° í´ë¦­í•˜ëŠ” í•¨ìˆ˜"""
    while True:
        try:
            button = page.locator(f".{button_class}")
            if not await button.is_visible():
                break
            await button.click()
            await asyncio.sleep(3)  # 3ì´ˆ ëŒ€ê¸°
        except Exception as e:
            print(f"ë²„íŠ¼ '{button_class}'ì´ ë” ì´ìƒ ë³´ì´ì§€ ì•Šê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            break

async def scrape_and_send_news():
    """
    Naver ë‰´ìŠ¤ ì–¸ë¡ ì‚¬ë³„ ë­í‚¹ì„ ìŠ¤í¬ë©í•˜ì—¬ ì œëª©ê³¼ ë§í¬ë¥¼ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    regDt = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Add current date and time
    print(f"[{regDt}] ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ë° ì „ì†¡ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    url = "https://news.naver.com/main/ranking/popularDay.naver"

    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            await page.goto(url)

            await click_until_disappear(page, "button_rankingnews_more")
            print("ë²„íŠ¼ í´ë¦­ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            all_components = soup.find('div', class_='_popularRanking')

            press_boxes = all_components.find_all('div', class_='rankingnews_box')
            print(f"ì´ {len(press_boxes)}ê°œì˜ ì–¸ë¡ ì‚¬ ë­í‚¹ ë°•ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            message_parts = []
            news_data = []  # Ensure news_data is initialized before use

            if not press_boxes:
                print("ì˜¤ë¥˜: ê°œë³„ ì–¸ë¡ ì‚¬ ë­í‚¹ ë°•ìŠ¤(class='rankingnews_box')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            current_time_str = escape_markdown_v2(datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ ê¸°ì¤€'))
            message_parts = [f"*{current_time_str} ì–¸ë¡ ì‚¬ë³„ ë‰´ìŠ¤ ë­í‚¹*"]

            for box in press_boxes:
                press_head = box.find('a', class_='rankingnews_box_head')
                # print("press_head : ", press_head)
                if not press_head:
                    continue

                press_name_tag = press_head.find('strong', class_='rankingnews_name')
                # print("press_name_tag : ", press_name_tag)
                if not press_name_tag:
                    continue

                press_name = escape_markdown_v2(press_name_tag.text.strip())
                message_parts.append(f"\nğŸ“° *{press_name}*")

                news_list = box.find('ul', class_='rankingnews_list')
                if not news_list:
                    continue

                articles = []
                for article in news_list.find_all('li'):
                    title_tag = article.find('a', class_='list_title')
                    if title_tag and title_tag.has_attr('href'):
                        title = title_tag.text.strip()
                        link = title_tag['href']
                        img_tag = article.find('img')  # img íƒœê·¸ ì¶”ì¶œ
                        img_src = img_tag['src'] if img_tag and img_tag.has_attr('src') else None  # img src ì¶”ì¶œ
                        time_tag = article.find('span', class_='list_time')  # span íƒœê·¸ì—ì„œ classê°€ list_timeì¸ ìš”ì†Œ ì¶”ì¶œ
                        time = time_tag.text.strip() if time_tag else None  # time ê°’ ì¶”ì¶œ
                        if not link.startswith('http'):
                            link = "https://news.naver.com" + link
                        articles.append({"title": title, "link": link, "img_src": img_src, "time": time})

                # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ news_data ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                
                new_entry = {"press_name": press_name, "articles": articles, "regDt": regDt}  # Add regDt to the same level as press_name
                news_data.append(new_entry)
            
            print("ëª¨ë“  ì–¸ë¡ ì‚¬ ë‰´ìŠ¤ ë­í‚¹ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

            # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
            if news_data:  # Ensure there is data to save
                try:
                    with open('news_data.json', 'r', encoding='utf-8') as json_file:
                        existing_data = json.load(json_file)
                except (FileNotFoundError, json.JSONDecodeError):
                    existing_data = []

                today_str = datetime.now().strftime('%Y-%m-%d')
                for item in existing_data:
                    regDt = item.get('regDt', '')
                    if not regDt.startswith(today_str):
                        item['articles'] = []

                for new_entry in news_data:
                    press_name = new_entry["press_name"]
                    articles = new_entry["articles"]

                    # Find existing press_name entry
                    existing_entry = next((item for item in existing_data if item["press_name"] == press_name), None)

                    if existing_entry:
                        existing_entry['regDt'] = regDt
                        for article in articles:
                            if not any(existing_article["title"] == article["title"] or existing_article["link"] == article["link"] for existing_article in existing_entry["articles"]):
                                existing_entry["articles"].insert(0, article)  # Add new articles at the beginning
                    else:
                        new_entry['regDt'] = regDt
                        existing_data.append(new_entry)

                with open('news_data.json', 'w', encoding='utf-8') as json_file:
                    json.dump(existing_data, json_file, ensure_ascii=False, indent=4)
                print("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ news_data.json íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            else:
                print("ì €ì¥í•  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            final_message = "\n".join(message_parts)

            if len(final_message.strip()) <= len(message_parts[0]):
                print("ì „ì†¡í•  ë‰´ìŠ¤ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì‹± ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            print("final_message ê¸¸ì´:", len(final_message))
            if len(final_message) > 4096:
                final_message = final_message[:4090] + "..."
                print("ê²½ê³ : ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë¥¼ ì˜ëìŠµë‹ˆë‹¤.")
            # print("ìµœì¢… ë©”ì‹œì§€:\n", final_message)

            # bot = Bot(token=TELEGRAM_BOT_TOKEN)
            # await bot.send_message(
            #     chat_id=TELEGRAM_CHAT_ID,
            #     text=final_message,
            #     parse_mode=ParseMode.MARKDOWN_V2,
            #     disable_web_page_preview=True
            # )
            # print("ë©”ì‹œì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.")
    except requests.exceptions.RequestException as e:
        print(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    except telegram.error.TelegramError as e:
        print(f"í…”ë ˆê·¸ë¨ API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        print(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        try:
            await browser.close()
        except NameError:
            print("'browser' ê°ì²´ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    print("ìŠ¤í¬ë¦½íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ 1íšŒ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    asyncio.run(scrape_and_send_news())
